
## 1. ¬øQu√© es pgstream?

**pgstream** es una herramienta de captura de datos de cambios (CDC) de c√≥digo abierto, dise√±ada espec√≠ficamente para PostgreSQL. Su funci√≥n principal es "escuchar" los cambios que ocurren en tu base de datos (INSERTs, UPDATEs, DELETEs) y transmitirlos en tiempo real a otros destinos.

### ¬øQui√©n lo desarroll√≥ y bajo qu√© licencia?

* **Desarrollador:** Fue creado y es mantenido principalmente por **Xata** (una plataforma de base de datos "serverless" basada en PostgreSQL).
* **Licencia:** Es **Open Source** (gratis) bajo la licencia **Apache 2.0**. No es de pago, aunque Xata lo utiliza como parte de su infraestructura comercial, el binario y el c√≥digo son libres para la comunidad.

---

## 2. ¬øPara qu√© sirve y por qu√© usarlo en vez del modo nativo?

Aunque PostgreSQL tiene **Replicaci√≥n L√≥gica nativa**, tiene limitaciones que pgstream resuelve de forma elegante:

| Caracter√≠stica | Replicaci√≥n L√≥gica Nativa | pgstream |
| --- | --- | --- |
| **Cambios de Esquema (DDL)** | No los replica autom√°ticamente. Si a√±ades una columna, la replicaci√≥n se rompe. | **Soporta DDL.** Rastrea cambios de esquema y los propaga al destino. |
| **Destinos** | Principalmente otro Postgres. | Postgres, **Elasticsearch, OpenSearch, Webhooks** y Kafka. |
| **Transformaci√≥n** | Limitada. | Permite transformar datos en el vuelo (ej. anonimizaci√≥n). |
| **Facilidad de uso** | Requiere gesti√≥n manual de slots y publicaciones. | Automatiza la creaci√≥n de slots y la gesti√≥n del estado. |

**¬øPor qu√© usarlo?** √ösalo si necesitas sincronizar tu base de datos con un motor de b√∫squeda (Elasticsearch), si necesitas reaccionar a eventos v√≠a Webhooks, o si tu esquema de base de datos cambia frecuentemente y no quieres que la replicaci√≥n falle cada vez que ejecutas un `ALTER TABLE`.

---

## 3. Casos de Uso Comunes

1. **Sincronizaci√≥n con Buscadores:** Mantener un √≠ndice de Elasticsearch/OpenSearch perfectamente sincronizado con tus tablas SQL para b√∫squedas r√°pidas.
2. **Arquitectura de Microservicios:** Notificar a otros servicios mediante Webhooks cada vez que un registro importante cambie.
3. **Auditor√≠a y An√°lisis:** Enviar un flujo de cambios a un Data Lake o sistema de anal√≠tica sin sobrecargar la base de datos principal con consultas pesadas.
4. **Migraciones con Tiempo de Inactividad Cero:** Replicar datos de una base de datos antigua a una nueva, incluyendo los cambios de estructura que ocurran durante el proceso.

---

## 4. Competidores Principales

* **Debezium:** El est√°ndar de la industria (basado en Java/Kafka). Es m√°s potente pero mucho m√°s complejo de configurar.
* **pglogical:** Una extensi√≥n de 2ndQuadrant (ahora EDB) que fue precursora de la replicaci√≥n l√≥gica nativa.
* **Sequin:** Una alternativa moderna enfocada en flujos de datos tipo "stream".
* **AWS Database Migration Service (DMS):** La opci√≥n gestionada si est√°s en la nube de Amazon.


---


# üèóÔ∏è Escenario Profesional: Sincronizaci√≥n Transaccional a Motor de B√∫squeda

### El Problema

Una plataforma de E-commerce tiene su base de datos **PostgreSQL** saturada por consultas de b√∫squeda de productos (`LIKE %termino%`). El equipo de infraestructura decide delegar las b√∫squedas a **OpenSearch**, pero necesitan que la sincronizaci√≥n sea en milisegundos y que, si el DBA agrega una columna de "Descuento" en Postgres, esta aparezca autom√°ticamente en OpenSearch sin romper el flujo.

### Objetivos del Laboratorio

1. Configurar **PostgreSQL** como fuente de eventos (Source).
2. Desplegar **pgstream** como orquestador de CDC en un nodo intermedio.
3. Sincronizar cambios hacia **OpenSearch** (Sink).
4. Demostrar la resiliencia ante cambios de esquema (DDL).

---

## üìã Inventario de Infraestructura

| Hostname | Direcci√≥n IP | Componente Instalado | Rol |
| --- | --- | --- | --- |
| `db-prod-01` | `10.0.1.10` | PostgreSQL 16 | Fuente de datos (Primary) |
| `stream-bridge-01` | `10.0.1.20` | **pgstream** v1.0 | Procesador de eventos |
| `search-node-01` | `10.0.1.30` | OpenSearch 2.x | Destino de b√∫squeda |

---

## üõ†Ô∏è Gu√≠a de Instalaci√≥n y Configuraci√≥n

### 1. Configuraci√≥n del Servidor de Base de Datos (`10.0.1.10`)

Instalamos y preparamos Postgres para replicaci√≥n l√≥gica.

* **Archivo:** `/etc/postgresql/16/main/postgresql.conf`
```ini
listen_addresses = '*'
wal_level = logical
max_replication_slots = 10
max_wal_senders = 10

```


* **Archivo:** `/etc/postgresql/16/main/pg_hba.conf`
```text
host  all  all  10.0.1.20/32  scram-sha-256
host  replication  all  10.0.1.20/32  scram-sha-256

```


* **SQL Preparaci√≥n:**
```sql
CREATE USER replicador WITH REPLICATION PASSWORD 'Pass_Stream_2026';
CREATE DATABASE ecommerce_db;
GRANT ALL PRIVILEGES ON DATABASE ecommerce_db TO replicador;

```



### 2. Configuraci√≥n del Bridge de Datos (`10.0.1.20`)

Aqu√≠ instalamos **pgstream**. No requiere base de datos propia, pero usa una tabla interna en el origen para el control de posici√≥n (LSN).

* **Instalaci√≥n:**
```bash
curl -L https://github.com/xataio/pgstream/releases/download/v1.0/pgstream_linux_amd64 -o /usr/local/bin/pgstream
chmod +x /usr/local/bin/pgstream

```


* **Inicializaci√≥n del esquema de control:**
```bash
pgstream init --postgres-url "postgres://replicador:Pass_Stream_2026@10.0.1.10:5432/ecommerce_db"

```



### 3. Ejecuci√≥n del Flujo de Datos

Configuramos pgstream para que tome los datos de Postgres y los env√≠e al nodo de b√∫squeda.

* **Comando de Producci√≥n:**
```bash
pgstream run \
  --postgres-url "postgres://replicador:Pass_Stream_2026@10.0.1.10:5432/ecommerce_db" \
  --sink-type opensearch \
  --opensearch-url "http://10.0.1.30:9200" \
  --opensearch-index "productos_idx" \
  --handle-ddl=true

```



---

## üß™ Pruebas de Validaci√≥n (Uso Com√∫n)

### Caso A: Inserci√≥n de datos en tiempo real

En el servidor `10.0.1.10`:

```sql
\c ecommerce_db
CREATE TABLE productos (id SERIAL PRIMARY KEY, nombre TEXT, precio NUMERIC);
INSERT INTO productos (nombre, precio) VALUES ('Laptop Pro 2026', 2500.00);

```

**Resultado:** En menos de 100ms, el documento aparece en `http://10.0.1.30:9200/productos_idx/_search`.

### Caso B: Cambio de Esquema (El "Killer Feature")

A diferencia de la replicaci√≥n nativa, pgstream no se detendr√° aqu√≠:

```sql
ALTER TABLE productos ADD COLUMN stock INTEGER DEFAULT 0;
UPDATE productos SET stock = 50 WHERE id = 1;

```

**Validaci√≥n:** pgstream detecta el `ALTER TABLE`, actualiza el mapeo en OpenSearch y el nuevo campo `stock` es indexado autom√°ticamente.

---

## üìà ¬øPor qu√© esta arquitectura es superior a la nativa?

1. **Desacoplamiento:** Si OpenSearch (`10.0.1.30`) cae, pgstream mantiene el puntero en Postgres y reanuda cuando el servicio vuelve, sin perder datos.
2. **Transformaci√≥n:** Podr√≠as a√±adir un flag `--transform` para que los precios se conviertan de USD a EUR antes de llegar al buscador.
3. **Mantenimiento:** No tienes que recrear suscripciones manualmente cada vez que haces un cambio en el DDL de la tabla.

---




## üîç ¬øD√≥nde est√°n la Publicaci√≥n y la Suscripci√≥n?

En la replicaci√≥n l√≥gica nativa de PostgreSQL, t√∫ tienes que hacer el `CREATE PUBLICATION` y el `CREATE SUBSCRIPTION` manualmente. Sin embargo, **pgstream automatiza la creaci√≥n de la infraestructura l√≥gica** por ti para evitar errores humanos.


Cuando ejecutaste el comando `pgstream init` y luego `pgstream run`, la herramienta realiz√≥ las siguientes acciones en tu servidor `10.0.1.10`:

### 1. La Publicaci√≥n (Autom√°tica)

Si entras a tu base de datos y ejecutas `SELECT * FROM pg_publication;`, ver√°s que pgstream cre√≥ una llamada (normalmente) `pgstream_pub`.

* **Por defecto:** pgstream crea una publicaci√≥n `FOR ALL TABLES`. Esto lo hace para cumplir con el objetivo del laboratorio: que cualquier tabla nueva (como `productos`) se replique sin que t√∫ tengas que intervenir.

### 2. El Slot de Replicaci√≥n (Suscripci√≥n L√≥gica)

En lugar de una "Suscripci√≥n" formal (que es un objeto que vive en otro Postgres), pgstream crea un **Logical Replication Slot**.

* Puedes verlo con: `SELECT * FROM pg_replication_slots;`.
* Este slot es el que mantiene el puntero (LSN) para que, si apagas pgstream, Postgres guarde los cambios en el WAL hasta que el bridge vuelva a conectarse.
 
## üõ†Ô∏è Modificaci√≥n del Laboratorio: Control Manual Profesional

Si en tu empresa te exigen que **NO** se repliquen todas las tablas (por seguridad o rendimiento), debes modificar los pasos del laboratorio de la siguiente manera:

### Paso A: Crear la Publicaci√≥n Manualmente (`10.0.1.10`)

Antes de correr pgstream, t√∫ decides qu√© se va.

```sql
\c ecommerce_db
-- Solo queremos replicar la tabla de productos, ignorando tablas sensibles como 'pagos'
CREATE PUBLICATION pub_busqueda_productos FOR TABLE productos;

```

### Paso B: Configurar la Identidad de Replicaci√≥n

Para que el CDC sepa qu√© registro borrar o actualizar en OpenSearch, la tabla debe tener una identidad clara.

```sql
ALTER TABLE productos REPLICA IDENTITY DEFAULT; -- Usa la Primary Key

```

### Paso C: Ejecutar pgstream apuntando a esa Publicaci√≥n (`10.0.1.20`)

Ahora le dices a pgstream que no cree nada autom√°tico, sino que use tu configuraci√≥n:

```bash
pgstream run \
  --postgres-url "postgres://replicador:Pass_Stream_2026@10.0.1.10:5432/ecommerce_db" \
  --publication-name "pub_busqueda_productos" \
  --replication-slot-name "slot_opensearch_prod" \
  --sink-type opensearch \
  --opensearch-url "http://10.0.1.30:9200"

```

---

## üìù Resumen de Objetivos vs. Implementaci√≥n

| Concepto | Qui√©n lo gestiona | Ubicaci√≥n | Por qu√© no lo viste antes |
| --- | --- | --- | --- |
| **Publicaci√≥n** | pgstream (Auto) | `db-prod-01` | Para facilitar el soporte de DDL autom√°tico (`FOR ALL TABLES`). |
| **Suscripci√≥n** | pgstream (Bridge) | `stream-bridge-01` | pgstream act√∫a como el suscriptor din√°mico; no es un objeto est√°tico en SQL. |
| **Slot** | pgstream | `db-prod-01` | Se crea en el momento del `init` para asegurar que no se pierdan datos desde el segundo 1. |

**¬øPor qu√© es mejor as√≠?**
Si lo hicieras nativo (`CREATE SUBSCRIPTION`), necesitar√≠as otro PostgreSQL en el destino. Como tu destino es **OpenSearch**, no existe el objeto "Suscripci√≥n" all√°. **pgstream traduce** el protocolo de replicaci√≥n de Postgres al protocolo HTTP/JSON de OpenSearch.





--- 


### 1. El coraz√≥n de todo: El WAL (Write-Ahead Log)

En Postgres, cada vez que haces un `INSERT`, `UPDATE` o `DELETE`, antes de que los datos se escriban en las tablas permanentes, se guardan en un archivo diario de transacciones llamado **WAL**. Es la "caja negra" del avi√≥n.

`pgstream` no consulta tus tablas (`SELECT * FROM...`), lo cual ser√≠a lent√≠simo. En su lugar, **lee el WAL de forma secuencial**.

* **Eficiencia:** Leer el WAL es extremadamente r√°pido y no bloquea las filas ni las tablas.
* **Granularidad:** Sabe exactamente qu√© columna cambi√≥, el valor viejo y el valor nuevo.

### 2. ¬øC√≥mo sabe qu√© objetos transmitir? (Publicaciones)

Aqu√≠ es donde entra la configuraci√≥n. `pgstream` utiliza el concepto de **Publicaciones (Publications)** de PostgreSQL.

* **A nivel de Base de Datos:** Por defecto, puedes configurar `pgstream` para que escuche **toda la base de datos** (`FOR ALL TABLES`). Esto es √∫til en migraciones totales.
* **A nivel de Objeto (Tablas espec√≠ficas):** En un entorno profesional, esto es lo m√°s com√∫n. T√∫ defines una publicaci√≥n solo para las tablas que quieres sincronizar:
```sql
-- En Postgres (db-prod-01)
CREATE PUBLICATION pgstream_pub FOR TABLE productos, clientes, pedidos;

```


Cuando arrancas `pgstream`, le indicas que use esa publicaci√≥n espec√≠fica. **Cualquier cambio en otras tablas ser√° ignorado por pgstream**, ahorrando ancho de banda y CPU.

### 3. Identificaci√≥n de Identidad (Replica Identity)

Para que `pgstream` sepa qu√© registro actualizar en el destino (por ejemplo, en OpenSearch), necesita una "llave".

* Si haces un `UPDATE`, el WAL normalmente solo trae los datos nuevos.
* Para que `pgstream` sepa cu√°l era el valor anterior o la llave primaria exacta, debes configurar la **Identidad de Replicaci√≥n** en la tabla:
```sql
ALTER TABLE productos REPLICA IDENTITY FULL;

```


Esto le dice a Postgres: "Cuando algo cambie en esta tabla, escribe en el WAL tanto el valor viejo como el nuevo". As√≠ `pgstream` tiene la informaci√≥n completa para hacer el "match" en el destino.

### 4. El flujo l√≥gico de decisi√≥n

Cuando ocurre un evento, `pgstream` sigue este algoritmo interno:

1. **Captura:** Lee el LSN (puntero) actual del WAL.
2. **Filtro:** ¬øEste cambio pertenece a una tabla incluida en mi `PUBLICATION`?
* *No:* Lo descarta inmediatamente.
* *S√≠:* Pasa al siguiente paso.


3. **Decodificaci√≥n:** Usa un decodificador (como el que mencionaste, `wal2json`, o el nativo `pgoutput`) para convertir los bytes binarios del WAL en un JSON estructurado.
4. **Enrutamiento:** Seg√∫n el ID de la tabla, lo env√≠a al "Sink" (destino) correspondiente.

### 5. ¬øQu√© pasa con los esquemas (DDL)?

Esto es lo que diferencia a `pgstream` de un simple script:
`pgstream` monitorea las tablas del sistema de Postgres (`pg_class`, `pg_attribute`). Cuando detecta un comando `ALTER TABLE`, actualiza su **cach√© de esquemas** interno.

* Si entra un cambio para una columna que no exist√≠a hace 10 segundos, `pgstream` consulta su cach√©, ve que el esquema cambi√≥, y ajusta el mensaje que env√≠a a OpenSearch para que el destino no rechace el dato por "formato inv√°lido".

---

### Resumen T√©cnico para el Laboratorio:

* **√Åmbito:** T√∫ decides. Puedes replicar una tabla, un grupo de tablas o la DB entera.
* **Costo de rendimiento:** M√≠nimo (lectura secuencial de logs).
* **Precisi√≥n:** Total. Al basarse en el WAL, si una transacci√≥n hace `ROLLBACK` en Postgres, `pgstream` nunca la ver√°, asegurando que solo los datos confirmados (`COMMITTED`) lleguen al destino.
 
 
---




---

### 1. Nivel Base de Datos (Default)

por defecto la configuraci√≥n inicial de pgstream es "agresiva": intenta replicar **todo el esquema** de la base de datos para asegurar que no se pierda ning√∫n cambio de estructura (DDL).

Sin embargo, en un entorno **profesional**, replicar toda la base de datos es a menudo un error de dise√±o (puedes saturar la red o exponer datos sensibles). Como experto, te confirmo que tienes **tres niveles de granularidad** para decidir qu√© se transmite:


Es lo que vimos en el primer comando. `pgstream` crea una publicaci√≥n `FOR ALL TABLES`.

* **Ventaja:** Cero configuraci√≥n. Ideal si el destino es un Data Lake donde quieres "todo".
* **Desventaja:** Si tienes una tabla de `logs_auditoria` con millones de registros que no necesitas en el buscador, vas a desperdiciar recursos.

### 2. Nivel por Filtro de Tabla (Recomendado)

Puedes restringir qu√© tablas lee el binario de `pgstream` mediante la configuraci√≥n de inclusi√≥n/exclusi√≥n. Esto se hace en el comando de ejecuci√≥n:

```bash
pgstream run \
  --postgres-url "..." \
  --include-tables "public.productos,public.categorias" \
  --exclude-tables "public.passwords,public.sesiones" \
  --sink-type opensearch

```

* **C√≥mo funciona:** `pgstream` recibe todos los cambios del WAL, pero descarta en memoria los que no coinciden con tu lista de inclusi√≥n antes de enviarlos al destino.

### 3. Nivel por Publicaci√≥n (El m√°s eficiente)

Este es el nivel "Cirujano". T√∫ controlas desde el mismo motor de PostgreSQL qu√© datos salen del disco.

1. **En Postgres:** Creas una publicaci√≥n que solo incluya lo necesario.
```sql
CREATE PUBLICATION pub_buscador_ecommerce FOR TABLE productos, stock_tiendas;

```


2. **En pgstream:** Le obligas a usar esa publicaci√≥n:
```bash
pgstream run --publication-name "pub_buscador_ecommerce" ...

```



* **Por qu√© es mejor:** Si una tabla no est√° en la publicaci√≥n, Postgres ni siquiera se molesta en enviarla a trav√©s del slot de replicaci√≥n, ahorrando CPU en el servidor de base de datos.

---

## üõ†Ô∏è El Laboratorio "Filtrado": Control de Objetos

Si quisi√©ramos que nuestro laboratorio profesional solo replique la tabla `productos` y no otras, el flujo real de comandos ser√≠a este:

**Servidor `10.0.1.10` (Postgres):**

```sql
-- Creamos dos tablas
CREATE TABLE productos (id int primary key, nombre text);
CREATE TABLE secretos_nomina (id int primary key, salario numeric);

-- Solo exponemos productos
CREATE PUBLICATION pub_limitada FOR TABLE productos;

```

**Servidor `10.0.1.20` (pgstream):**

```bash
pgstream run \
  --postgres-url "..." \
  --publication-name "pub_limitada" \
  --sink-type opensearch

```

**Resultado:** Cualquier `INSERT` en `productos` viajar√° a OpenSearch. Cualquier cambio en `secretos_nomina` ser√° ignorado por completo por el proceso de stream.

---

### ‚ö†Ô∏è Una advertencia de experto: La Identidad de la Tabla

Si decides filtrar y solo enviar ciertas tablas, no olvides que cada tabla debe tener definida su **Replica Identity**. Si una tabla no tiene Primary Key y no configuras `REPLICA IDENTITY FULL`, los `UPDATE` y `DELETE` llegar√°n vac√≠os o dar√°n error porque pgstream no sabr√° a qu√© fila se refieren.



# Links
```
https://github.com/xataio/pgstream
https://xata.io/blog/pgstream-v100-stateless-schema-change-replication
```
