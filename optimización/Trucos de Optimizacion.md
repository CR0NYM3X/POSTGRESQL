

# Consultas que parecen perfectas‚Ä¶ pero no lo son: los JOINs que arruinan tu performance [[Ref]](https://medium.com/@Rohan_Dutt/how-to-write-sql-queries-that-prevent-cardinality-explosions-in-multi-way-joins-b41ba236acac)

 
### **1. JOIN sobre columnas con tipos diferentes (impl√≠cito CAST)**

*   **Raz√≥n:** Si las columnas tienen tipos distintos (ej. `INT` vs `VARCHAR`), el motor hace conversi√≥n en cada comparaci√≥n ‚Üí **no usa √≠ndice**.
*   **Ejemplo del problema:**
    ```sql
    SELECT * 
    FROM pedidos p
    JOIN clientes c ON p.id_cliente = c.id_cliente::text;
    ```
    Parece correcto, pero el CAST rompe el √≠ndice.
*   **Soluci√≥n:**
    *   Asegurar tipos iguales en dise√±o.
    *   O usar CAST en la columna m√°s peque√±a y crear √≠ndice funcional:
        ```sql
        CREATE INDEX idx_clientes_id_text ON clientes((id_cliente::text));
        ```



### **2. JOIN con funci√≥n en la condici√≥n**

*   **Raz√≥n:** Usar funciones en la columna del JOIN invalida el √≠ndice.
*   **Ejemplo del problema:**
    ```sql
    SELECT * 
    FROM ventas v
    JOIN productos p ON LOWER(v.codigo) = LOWER(p.codigo);
    ```
    Parece bien para case-insensitive, pero fuerza **full scan**.
*   **Soluci√≥n:**
    *   Crear √≠ndice funcional:
        ```sql
        CREATE INDEX idx_productos_lower ON productos(LOWER(codigo));
        ```
    *   Evitar aplicar funci√≥n en ambas columnas.



### **3. JOIN con OR en la condici√≥n**

*   **Raz√≥n:** Condiciones con `OR` en el `ON` hacen que el optimizador no use √≠ndices eficientemente.
*   **Ejemplo del problema:**
    ```sql
    SELECT * 
    FROM clientes c
    JOIN pedidos p ON c.id_cliente = p.id_cliente OR c.email = p.email_cliente;
    ```
*   **Soluci√≥n:**
    *   Separar en dos consultas y unir con `UNION ALL`:
        ```sql
        SELECT ... FROM clientes c JOIN pedidos p ON c.id_cliente = p.id_cliente
        UNION ALL
        SELECT ... FROM clientes c JOIN pedidos p ON c.email = p.email_cliente;
        ```



### **4. JOIN con ORDER BY en columna no indexada**

*   **Raz√≥n:** Si ordenas por una columna que no est√° indexada despu√©s de un JOIN grande, el motor hace **sort costoso en memoria**.
*   **Ejemplo del problema:**
    ```sql
    SELECT c.nombre, p.total
    FROM clientes c
    JOIN pedidos p ON c.id_cliente = p.id_cliente
    ORDER BY p.fecha_pedido;
    ```
*   **Soluci√≥n:**
    ```sql
    CREATE INDEX idx_pedidos_fecha ON pedidos(fecha_pedido);
    ```



### **5. JOIN con subconsulta no correlacionada mal optimizada**

*   **Raz√≥n:** Subconsultas en el `ON` o `WHERE` que parecen simples pueden generar **Nested Loop gigante**.
*   **Ejemplo del problema:**
    ```sql
    SELECT c.nombre, p.total
    FROM clientes c
    JOIN pedidos p ON c.id_cliente = p.id_cliente
    WHERE p.total > (SELECT AVG(total) FROM pedidos);
    ```
    Parece bien, pero el optimizador recalcula el AVG muchas veces.
*   **Soluci√≥n:**
    ```sql
    WITH avg_total AS (SELECT AVG(total) AS promedio FROM pedidos)
    SELECT c.nombre, p.total
    FROM clientes c
    JOIN pedidos p ON c.id_cliente = p.id_cliente
    CROSS JOIN avg_total
    WHERE p.total > avg_total.promedio;
    ```
 

### ‚úÖ **¬øQu√© riesgos hay si no haces JOINs inteligentes?**

Si no consideras la cardinalidad y haces JOINs incorrectos, puedes tener:

1.  **Duplicaci√≥n masiva de datos**
    *   Si haces un JOIN sin condiciones correctas, puedes multiplicar filas (efecto ‚Äúcartesiano‚Äù).
    *   Ejemplo: `SELECT * FROM clientes JOIN pedidos;` sin `ON` ‚Üí millones de combinaciones.

2.  **Resultados incorrectos**
    *   Datos inflados, totales err√≥neos, reportes falsos.
    *   Ejemplo: sumas que deber√≠an dar 100, terminan en 10,000 por duplicaci√≥n.

3.  **Problemas de rendimiento**
    *   JOINs mal dise√±ados pueden generar consultas lent√≠simas, bloqueos y alto consumo de CPU/memoria.

4.  **Riesgo de inconsistencias**
    *   Si no respetas la cardinalidad, puedes mostrar datos que no tienen relaci√≥n real (errores l√≥gicos).

5.  **Impacto en integridad y seguridad**
    *   JOINs incorrectos pueden exponer datos que no deber√≠an relacionarse, afectando privacidad.
 

‚úÖ **Buenas pr√°cticas para JOINs inteligentes:**

*   Analiza la cardinalidad antes de dise√±ar la consulta.
*   Usa claves primarias y for√°neas correctamente.
*   Evita `CROSS JOIN` salvo que sea necesario.
*   Usa `INNER JOIN`, `LEFT JOIN`, `RIGHT JOIN` seg√∫n el caso.
*   Filtra con condiciones claras (`ON` y `WHERE`).

 


---
# Los indices en columnas que estan en Group By sirven o no?

Decir que un √≠ndice en un `GROUP BY` "no sirve de nada" es incorrecto. De hecho, un √≠ndice bien dise√±ado es **crucial** para optimizar un `GROUP BY`.

Vamos a desglosarlo para que entiendas la mec√°nica interna de PostgreSQL y puedas rebatir con argumentos t√©cnicos superiores (o conceder la victoria elegantemente).

### ¬øPor qu√© un √≠ndice S√ç ayuda al GROUP BY?

Para que la base de datos pueda agrupar filas por `producto`, necesita poner todos los "relojes" juntos, todos los "zapatos" juntos, etc.

PostgreSQL tiene principalmente dos estrategias para hacer esto:

1. **HashAggregate (Sin √çndice):**
* Lee toda la tabla desordenada (Sequential Scan).
* Crea una tabla hash en memoria RAM.
* Va metiendo cada fila en su "cubeta" correspondiente.
* **Problema:** Consume mucha memoria (`work_mem`). Si la tabla es gigante, se desborda al disco y se vuelve lent√≠simo.


2. **GroupAggregate (Con √çndice):**
* Un √≠ndice B-Tree guarda los datos **ya ordenados**.
* PostgreSQL recorre el √≠ndice. Como ya viene ordenado (A, A, A, B, B, C...), sabe que en cuanto cambia de "A" a "B", ya termin√≥ de sumar las "A".
* **Ventaja:** No necesita memoria para ordenar ni hacer hash. Es un flujo continuo (streaming). El primer resultado sale casi instant√°neamente.



---

### La prueba del delito (Comparaci√≥n t√©cnica)

Supongamos tu tabla `inventario` con millones de filas.

#### Escenario 1: Tu postura (Sin √çndice o √çndice ignorado)

Postgres har√° esto:

```text
-> HashAggregate
   -> Seq Scan on inventario

```

*Costo:* Leer todo el disco + Costo de CPU para armar el hash.

#### Escenario 2: La postura del DBA (√çndice en `producto`)

Si creas `CREATE INDEX idx_producto ON inventario(producto);`
Postgres *podr√≠a* hacer esto:

```text
-> GroupAggregate
   -> Index Scan on idx_producto

```

*Costo:* Lee el √≠ndice ordenado. Pero ojo, **aqu√≠ tienes un punto a tu favor:** Si el √≠ndice solo tiene `producto`, Postgres tiene que ir a la tabla principal (Heap) a buscar el valor de `cantidad` para sumarlo. Si la tabla es muy grande, hacer esos saltos es lento y Postgres podr√≠a preferir no usar el √≠ndice.

#### Escenario 3: La t√©cnica Maestra (Covering Index)

Aqu√≠ es donde t√∫ puedes ganar el debate proponiendo la **soluci√≥n real**.
Si creas el √≠ndice as√≠:

```sql
CREATE INDEX idx_producto_covering ON inventario (producto) INCLUDE (cantidad);

```

O as√≠ (√≠ndice compuesto):

```sql
CREATE INDEX idx_producto_cantidad ON inventario (producto, cantidad);

```

Ocurre la magia llamada **Index Only Scan**.

1. Postgres va al √≠ndice.
2. El √≠ndice ya est√° ordenado por `producto` (perfecto para el Group By).
3. El √≠ndice *tambi√©n* contiene el valor de `cantidad`.
4. **Resultado:** Postgres **nunca toca la tabla**. Resuelve la consulta leyendo solo el √≠ndice, que es mucho m√°s peque√±o y r√°pido.

### Resumen del Veredicto

| Argumento | Validez | Explicaci√≥n |
| --- | --- | --- |
| **"El √≠ndice no sirve de nada" (T√∫)** | ‚ùå Incorrecto | Un √≠ndice evita la operaci√≥n de ordenamiento (Sort) que es muy costosa. |
| **"El √≠ndice s√≠ sirve" (DBA)** | ‚úÖ Correcto | Permite usar `GroupAggregate` en lugar de `HashAggregate`. |
| **"El √≠ndice optimizado" (T√∫ + Conocimiento)** | üöÄ Experto | Un √≠ndice con `INCLUDE` o compuesto permite un `Index Only Scan`, que es la forma m√°s r√°pida posible. |

### ¬øCu√°ndo tendr√≠as raz√≥n t√∫?

T√∫ tendr√≠as raz√≥n **solo si la cardinalidad es muy baja**.
Ejemplo: Si tu tabla tiene 1 mill√≥n de filas pero solo hay 2 tipos de productos ("A" y "B").
En ese caso, usar un √≠ndice es m√°s lento que leer toda la tabla de golpe, y el planificador de Postgres ignorar√° el √≠ndice del DBA. Pero en un inventario normal (muchos productos distintos), el √≠ndice gana.

### Paso siguiente sugerido

Para demostrar dominio del tema, te sugiero que no le digas "ten√≠as raz√≥n", sino que le digas:
*"Ten√≠as raz√≥n en que el √≠ndice ayuda a evitar el sort, pero si solo indexamos la columna del grupo, el salto al Heap es costoso. 


---

#  **No usar `SELECT *`**
 Razones t√©cnicas fundamentales por las que, a pesar de que la p√°gina se cargue completa en memoria, `SELECT *` sigue siendo una mala pr√°ctica de arquitectura y rendimiento.
 
### 1. El "Efecto TOAST" (El I/O oculto)

Aqu√≠ es donde falla tu teor√≠a de que "todo est√° en la p√°gina". PostgreSQL tiene un l√≠mite de tama√±o para las filas en una p√°gina de 8KB. Si tienes columnas grandes (como `TEXT` largo, `JSONB` pesado o `BYTEA`), Postgres usa una t√©cnica llamada **TOAST** (*The Oversized-Attribute Storage Technique*).

* **C√≥mo funciona:** Postgres mueve los datos grandes a una tabla "oculta" aparte.
* **El problema:** Si haces `SELECT *`, obligas a Postgres a ir a buscar esos datos a la tabla TOAST (I/O extra). Si solo haces `SELECT id, nombre`, Postgres **ni siquiera toca** los datos pesados, ahorrando much√≠simos recursos de disco y memoria.

### 2. Index-Only Scans (El "Santo Grial" del performance)

Esta es la raz√≥n m√°s pesada en arquitectura. Si tu consulta solo pide columnas que ya est√°n en un **√≠ndice**, PostgreSQL puede responderte **sin tocar la tabla (el Heap)**.

* **Con `SELECT id` (siendo ID indexado):** Postgres lee el √≠ndice y te da la respuesta. Es ultra r√°pido.
* **Con `SELECT *`:** Forzosamente tiene que ir a la tabla para traer las columnas que no est√°n en el √≠ndice. Esto convierte una consulta de microsegundos en una de milisegundos.

### 3. El costo de "Serializaci√≥n" y Red

Aunque la p√°gina de 8KB est√© en la memoria RAM (Buffer Cache), esos datos tienen que viajar al **cliente** (tu aplicaci√≥n en Python, Java, Node, etc.).

* **CPU:** Postgres tiene que "empaquetar" cada columna en el protocolo de red. M√°s columnas = m√°s ciclos de CPU en el servidor.
* **Ancho de Banda:** Si tu tabla tiene 50 columnas y solo usas 2, est√°s enviando un 95% de "basura" por el cable. En una red de nube (AWS/Azure) donde la latencia es ley, enviar megabytes extra de datos innecesarios satura la tarjeta de red y ralentiza la aplicaci√≥n.
* **Memoria en el Cliente:** Tu aplicaci√≥n tiene que "desempaquetar" y guardar en su propia RAM (objetos de lenguaje) todas esas columnas que no va a usar, lo cual puede causar problemas de *Garbage Collection* o falta de memoria.

### 4. Mantenimiento y Evoluci√≥n (Arquitectura)

Este punto no es de performance de CPU, sino de **resiliencia del sistema**:

* **Contratos:** Si tu aplicaci√≥n usa `SELECT *`, y ma√±ana alguien agrega una columna de tipo `GEOMETRY` o un `JSONB` de 10MB a esa tabla, tu aplicaci√≥n **heredar√° ese peso autom√°ticamente** y podr√≠a colapsar o volverse lenta sin que t√∫ hayas cambiado una sola l√≠nea de c√≥digo en el backend.

---

### Resumen para tus alumnos:

| Nivel | ¬øImporta `SELECT *`? | ¬øPor qu√©? |
| --- | --- | --- |
| **Disco/P√°ginas** | **Poco** | Tienes raz√≥n: se lee el bloque de 8KB completo del disco a la RAM. |
| **TOAST** | **Mucho** | Traer columnas grandes requiere leer archivos extra que no est√°n en la p√°gina principal. |
| **√çndices** | **Cr√≠tico** | `SELECT *` rompe la posibilidad de usar *Index-Only Scans*. |
| **Red** | **Mucho** | El tr√°fico de red y la serializaci√≥n crecen linealmente con el n√∫mero de columnas. |

> **Conclusi√≥n:** Tu l√≥gica sobre la carga de p√°ginas en el Buffer Cache es correcta para datos "peque√±os" y ya cargados, pero en el panorama completo de la arquitectura, los costos de TOAST, red y p√©rdida de optimizaciones de √≠ndice hacen que `SELECT *` sea un enemigo del escalado.



### Index-Only Scan

Para un arquitecto de bases de datos, entender el **Index-Only Scan** es como descubrir un "atajo m√°gico". Es una de las optimizaciones m√°s potentes de PostgreSQL porque permite que la base de datos responda una consulta **sin tocar la tabla (el Heap)**.

 

### 1. La diferencia fundamental

Para entenderlo, primero debemos recordar c√≥mo funciona un **Index Scan** normal (el est√°ndar):

1. **Busca en el √≠ndice:** Encuentra la entrada (por ejemplo, el ID 500).
2. **Obtiene el puntero:** El √≠ndice le dice: "Esa fila est√° en la P√°gina A, Fila 12".
3. **Va al Heap (La tabla):** Postgres tiene que saltar al disco/memoria para leer la fila completa en la tabla y verificar si la fila es visible para tu transacci√≥n (MVCC) y traer el resto de las columnas.

En un **Index-Only Scan**, Postgres hace esto:

1. **Busca en el √≠ndice:** Encuentra la entrada.
2. **Responde directamente:** Como el √≠ndice ya contiene la columna que pediste, y Postgres sabe que la fila es v√°lida, **no salta a la tabla**. Devuelve el dato inmediatamente desde el √≠ndice.

 

### 2. El requisito secreto: El "Visibility Map" (Mapa de Visibilidad)

Tus alumnos podr√≠an preguntar: *"¬øC√≥mo sabe Postgres si una fila ha sido borrada o actualizada por otra transacci√≥n si no lee la tabla?"* (Recuerda el sistema MVCC).

Aqu√≠ entra un componente de arquitectura clave: **El Visibility Map (VM)**.

* El VM es un archivo peque√±o que rastrea qu√© p√°ginas de la tabla solo contienen filas que son visibles para todos.
* Si la p√°gina en la tabla est√° marcada como **"all-visible"** en el mapa, Postgres conf√≠a en el √≠ndice y completa el **Index-Only Scan**.
* Si la p√°gina ha tenido cambios recientes y no es "all-visible", Postgres se ve obligado a ir a la tabla para verificar la visibilidad, perdiendo la optimizaci√≥n.

 

### 3. Ejemplo pr√°ctico para tu clase

Imagina esta tabla de usuarios con 10 millones de filas:

```sql
CREATE TABLE usuarios (
    id SERIAL PRIMARY KEY,
    nombre TEXT,
    email TEXT,
    fecha_registro TIMESTAMP,
    -- ... otras 20 columnas pesadas
);

CREATE INDEX idx_usuarios_email ON usuarios(email);

```

#### Caso A: El error del `SELECT *`

```sql
SELECT * FROM usuarios WHERE email = 'profe@ejemplo.com';

```

* **Postgres piensa:** "Tengo el email en el √≠ndice, pero el usuario quiere el nombre, la fecha y otras 20 columnas que NO est√°n en el √≠ndice. **Tengo que ir a la tabla forzosamente**".
* **Resultado:** Index Scan (m√°s lento).

#### Caso B: La eficiencia del Index-Only Scan

```sql
SELECT email FROM usuarios WHERE email = 'profe@ejemplo.com';

```

* **Postgres piensa:** "Busco el email y el usuario solo me pide el email. ¬°Ya lo tengo todo en el √≠ndice! No necesito leer la tabla".
* **Resultado:** **Index-Only Scan** (ultra r√°pido, cero I/O en la tabla).



### 4. ¬øPor qu√© es importante para el performance?

1. **Ahorro de I/O:** Evitas el "Random I/O" de saltar del √≠ndice a la tabla. El √≠ndice es mucho m√°s peque√±o y suele estar siempre en la RAM (Buffer Cache).
2. **Menos contenci√≥n:** Al no leer la tabla, reduces la carga en el sistema de almacenamiento.
3. **Sinergia con VACUUM:** Para que el *Visibility Map* est√© actualizado, el **autovacuum** debe correr con frecuencia. Si el vacuum no limpia, no hay Index-Only Scans.

### Resumen para tus alumnos:

> "Un Index-Only Scan es cuando el √≠ndice se vuelve la base de datos misma para esa consulta. Si pides solo lo que indexaste, Postgres no tiene que trabajar doble yendo a la tabla. Por eso el `SELECT *` es el enemigo de esta optimizaci√≥n: obliga a la base de datos a dejar de leer el √≠ndice (peque√±o y r√°pido) para ir a buscar basura a la tabla (grande y lenta)".

--- 
# On-Premise - Cloud [Link](https://www.scalingpostgres.com/episodes/398-latency-killing-performance/)

Este post de **Cybertec** es una pieza fundamental para tu curso de arquitectura, porque explica por qu√© una base de datos puede ser lenta aunque el procesador (CPU) sea el m√°s r√°pido del mundo. El culpable: **La latencia.**

Aqu√≠ tienes el resumen desglosado para que lo expliques a tus alumnos:

### 1. El Objetivo del Post

El autor busca demostrar con datos reales que la diferencia de rendimiento entre tener servidores f√≠sicos propios (**On-Premise**) y usar la nube (**Cloud**) no se debe a la potencia del equipo, sino a la **distancia f√≠sica y l√≥gica** que recorren los datos.

### 2. El Problema: Latencia vs. Rendimiento

El post explica que en PostgreSQL, la mayor√≠a de las operaciones (especialmente las escrituras) dependen de qu√© tan r√°pido el disco le diga a la base de datos: *"Ya guard√© la informaci√≥n"*.

* **En la nube (Cloud):** Tu base de datos y tu disco (almacenamiento) **no est√°n en el mismo lugar**. Est√°n conectados por una red interna. Cada vez que haces un `COMMIT`, el dato debe viajar por esa red, guardarse y enviar una confirmaci√≥n de vuelta.
* **En servidores f√≠sicos (On-Premise):** El disco suele estar conectado directamente a la placa base (bus local). El viaje es casi instant√°neo.

### 3. Conceptos Clave para tu clase

#### A. Latencia de Red (El "Ping")

El post muestra que en la nube, el simple hecho de enviar un paquete de un servidor a otro a√±ade milisegundos que en un servidor f√≠sico no existen.

* **Dato para alumnos:** Si una consulta hace 100 viajes de red peque√±os, y cada uno tarda 1ms, la consulta tardar√° 100ms solo en "viajes", sin contar el procesamiento.

#### B. Latencia de Disco (El problema del WAL)

PostgreSQL usa el **WAL (Write Ahead Log)**. Para que una transacci√≥n sea segura, el WAL debe escribirse en el disco de forma s√≠ncrona.

* En **On-premise** con discos NVMe, esto tarda unos **pocos microsegundos**.
* En **Cloud** (usando almacenamiento en red como AWS EBS), esto puede tardar **milisegundos**.
* **Conclusi√≥n:** La nube puede ser **10 o 50 veces m√°s lenta** en escrituras pesadas debido a esta arquitectura.

#### C. Rendimiento (Throughput) vs. Latencia

El post aclara que la nube es excelente en *Throughput* (puede mover mucha informaci√≥n a la vez), pero es mala en *Latencia* (qu√© tan r√°pido responde una sola petici√≥n). Para una base de datos transaccional, la latencia es mucho m√°s importante.

### 4. La Soluci√≥n / Recomendaciones

El post no dice que la nube sea mala, sino que como arquitecto debes saber elegir:

1. **Si necesitas velocidad extrema:** Usa servidores f√≠sicos o instancias de nube con "Local NVMe" (como el post de PlanetScale Metal que vimos antes).
2. **Si usas nube est√°ndar:** Debes optimizar tu c√≥digo para hacer **menos viajes al servidor** (usar procedimientos almacenados, reducir el n√∫mero de commits peque√±os, o usar conexiones persistentes).



### Resumen Ejecutivo para tu curso:

> "La nube es como pedir comida por delivery: puedes pedir mucha comida (Throughput), pero siempre tardar√° en llegar porque tiene que viajar por la calle (Red). Tener el servidor f√≠sico es como cocinar en tu propia cocina: es inmediato porque todo est√° a la mano."

 
 


---

# shared_buffers

El par√°metro `shared_buffers` no es una "isla"; su configuraci√≥n impacta y depende directamente de otros valores dentro de PostgreSQL y de la configuraci√≥n del n√∫cleo (kernel) de Linux.

Aqu√≠ te detallo c√≥mo se relaciona con el ecosistema del servidor para que puedas ajustarlo correctamente:



## 1. Relaci√≥n con otros par√°metros de PostgreSQL

`shared_buffers` determina cu√°nta memoria RAM reserva PostgreSQL para su propia cach√© de datos. Si lo mueves, debes considerar estos otros:

* **`max_connections`**: Cada conexi√≥n consume una cantidad peque√±a pero acumulativa de memoria RAM. Si subes mucho los `shared_buffers` y tambi√©n tienes un `max_connections` muy alto, podr√≠as quedarte sin RAM para los procesos individuales.
* **`work_mem`**: Esta es la memoria para operaciones de ordenamiento (sort) y uniones (hash joins). A diferencia de `shared_buffers`, que es global, `work_mem` se asigna **por cada operaci√≥n dentro de una consulta**. Si asignas el 80% de tu RAM a `shared_buffers`, no dejar√°s espacio para que `work_mem` funcione, provocando que las consultas usen el disco (lento) o que el sistema colapse (OOM Killer).
* **`effective_cache_size`**: No reserva memoria, pero le dice al optimizador cu√°nta memoria crees que hay disponible en total (incluyendo la cach√© del Sistema Operativo). T√≠picamente se configura al **50% - 75%** de la RAM total.
* **`huge_pages`**: Si tu `shared_buffers` es mayor a unos pocos gigabytes, es casi obligatorio usar Huge Pages en Linux para mejorar el rendimiento y reducir la sobrecarga de la CPU al gestionar tablas de p√°ginas grandes.
 
### L√≠mites de Memoria Compartida (Kernel Parameters)

En versiones modernas de PostgreSQL (9.3+), el uso de memoria compartida es m√°s flexible, pero en sistemas muy cargados o versiones antiguas, debes revisar el archivo `/etc/sysctl.conf`:

* **`kernel.shmmax`**: Es el tama√±o m√°ximo de un solo segmento de memoria compartida. Debe ser mayor que tu `shared_buffers`.
* **`kernel.shmall`**: Es la cantidad total de memoria compartida permitida en el sistema (en p√°ginas).

### Huge Pages (P√°ginas Grandes)

Si configuras `shared_buffers` con un valor alto (ej. 16GB o m√°s), el kernel de Linux gastar√° mucha CPU gestionando p√°ginas est√°ndar de 4KB. Configurar **Huge Pages** (generalmente de 2MB) permite que el kernel gestione esa memoria de forma mucho m√°s eficiente.

* Debes reservar las p√°ginas en Linux: `vm.nr_hugepages`.
* Y activar el par√°metro en Postgres: `huge_pages = try` o `on`.

### Swappiness

* **`vm.swappiness`**: Se recomienda bajar este valor a **1** o **10**. Esto evita que Linux mueva datos de la RAM (de tus buffers) al disco (swap) prematuramente, lo cual destruir√≠a el rendimiento de tu base de datos.



Estos par√°metros son **configuraciones del n√∫cleo (kernel) de Linux** y se gestionan fuera de PostgreSQL, directamente en el sistema operativo. Tienes dos formas de hacerlo: una temporal (para probar) y una permanente (para que no se pierda al reiniciar).

Aqu√≠ te explico c√≥mo y d√≥nde hacerlo:



## 1. Configuraci√≥n Permanente (Recomendado)

Para que los cambios persistan despu√©s de un reinicio, debes editar el archivo `/etc/sysctl.conf` o crear un archivo nuevo en `/etc/sysctl.d/`.

### Pasos:

1. Abre el archivo con privilegios de administrador:
```bash
sudo nano /etc/sysctl.conf

```


2. Ve al final del archivo y agrega las l√≠neas con los valores que necesites. Por ejemplo:
```text
# Optimizaci√≥n para PostgreSQL
vm.swappiness = 10
vm.nr_hugepages = 4096
kernel.shmmax = 18446744073709551615
kernel.shmall = 18446744073709551615

```


3. Guarda el archivo y cierra (`Ctrl+O`, `Enter`, `Ctrl+X`).
4. **Carga los cambios inmediatamente** sin reiniciar el servidor con este comando:
```bash
sudo sysctl -p

```

 

## 2. Configuraci√≥n Temporal (Para pruebas)

Si solo quieres probar el impacto en el rendimiento sin comprometer el pr√≥ximo inicio del sistema, puedes usar el comando `sysctl -w`:

```bash
sudo sysctl -w vm.swappiness=10
sudo sysctl -w vm.nr_hugepages=4096

```

*Nota: Estos valores se borrar√°n si el servidor se apaga o se reinicia.*



## 3. ¬øC√≥mo saber qu√© valores poner?

No se trata de poner n√∫meros al azar, especialmente con las **Huge Pages**. Aqu√≠ te doy una gu√≠a r√°pida:

### Para `vm.swappiness`:

* **Valor 60 (Default):** Linux mueve datos a la swap con frecuencia. Malo para bases de datos.
* **Valor 1 a 10:** Recomendado para PostgreSQL. Le dice al kernel: "No uses el disco a menos que sea estrictamente necesario".

### Para `vm.nr_hugepages`:

Este valor depende totalmente de tu `shared_buffers`. Si pones un n√∫mero muy peque√±o, Postgres no arrancar√°; si pones uno muy grande, desperdiciar√°s RAM que nadie m√°s podr√° usar.

**La f√≥rmula b√°sica es:**


> **Ejemplo:** Si tu `shared_buffers` es de 8GB ( KB):
>  p√°ginas.



## 4. Verificaci√≥n

Despu√©s de aplicar los cambios, puedes verificar que el sistema los tom√≥ correctamente con:

* **Para ver swappiness:** `cat /proc/sys/vm/swappiness`
* **Para ver p√°ginas grandes:** `grep Huge /proc/meminfo`

 
