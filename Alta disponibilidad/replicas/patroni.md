## ðŸ§  3. Â¿QuÃ© es Patroni?

**Patroni** es una herramienta de **orquestaciÃ³n de alta disponibilidad** para PostgreSQL. Utiliza un sistema de consenso distribuido (como **Etcd**, **Consul** o **ZooKeeper**) para coordinar quÃ© nodo debe ser el **lÃ­der (primary)** y cuÃ¡les deben ser los **replicas (standby)**.


## âœ… 4. Ventajas de usar Patroni

| Ventaja                            | DescripciÃ³n                                                                     |
| ---------------------------------- | ------------------------------------------------------------------------------- |
| ðŸ”„ **Failover automÃ¡tico**         | Detecta caÃ­das del nodo primario y promueve un standby sin intervenciÃ³n humana. |
| ðŸ§© **IntegraciÃ³n con etcd/consul** | Usa sistemas de consenso para evitar split-brain y asegurar consistencia.       |
| ðŸ› ï¸ **ConfiguraciÃ³n flexible**     | Compatible con mÃºltiples entornos: bare metal, contenedores, Kubernetes.        |
| ðŸ“¡ **API REST**                    | Expone endpoints para monitoreo y control externo.                              |
| ðŸ” **Seguridad y control**         | Puede integrarse con sistemas de autenticaciÃ³n y cifrado.                       |


 
***
 

## ðŸ“… 7. CuÃ¡ndo usar Patroni

*   Cuando necesitas **alta disponibilidad automÃ¡tica** sin intervenciÃ³n humana.
*   Cuando tu entorno requiere **replicaciÃ³n sÃ­ncrona o asÃ­ncrona**.
*   Cuando trabajas en **Kubernetes** y necesitas una soluciÃ³n HA nativa.
*   Cuando tienes mÃºltiples nodos PostgreSQL y quieres evitar el split-brain.


--- 

***




## âš ï¸ Consideraciones clave antes de instalar

### ðŸ”¹ 1. SeparaciÃ³n de roles

*   No mezcles etcd con PostgreSQL en producciÃ³n.
*   Patroni debe tener acceso exclusivo al PostgreSQL local.

### ðŸ”¹ 2. Recursos dedicados

*   etcd requiere poca CPU/RAM, pero necesita estabilidad.
*   PostgreSQL debe tener prioridad en disco y memoria.

### ðŸ”¹ 3. Red y puertos

*   AsegÃºrate de que todos los nodos puedan comunicarse entre sÃ­.
*   Usa IPs fijas o DNS internos.

### ðŸ”¹ 4. Seguridad

*   Usa TLS en etcd y Patroni si estÃ¡s en producciÃ³n.
*   Configura firewalls internos para limitar acceso.

--- 

## ðŸ§© Â¿QuÃ© puede estar junto en el mismo servidor?

| CombinaciÃ³n           | Â¿Es recomendable?                      | JustificaciÃ³n                                                                                   |
| --------------------- | -------------------------------------- | ----------------------------------------------------------------------------------------------- |
| Patroni + PostgreSQL  | âœ… SÃ­                                   | Patroni necesita acceso directo al PostgreSQL local para controlarlo.                           |
| Patroni + etcd        | âš ï¸ Solo en entornos pequeÃ±os o pruebas | En producciÃ³n, etcd debe estar separado para evitar que un fallo en Patroni afecte el consenso. |
| etcd + etcd (clÃºster) | âœ… SÃ­                                   | etcd debe estar en al menos 3 nodos distintos para lograr consenso.                             |
| PostgreSQL + etcd     | âŒ No recomendado                       | Si el nodo cae, se pierde tanto la base de datos como el consenso.                              |
| Patroni + HAProxy     | âœ… SÃ­                                   | Patroni puede convivir con balanceadores si el servidor tiene recursos suficientes.             |

***

## ðŸ§  CuÃ¡ndo escalar

*   **Escala Patroni + PostgreSQL** cuando necesites mÃ¡s rÃ©plicas para lectura.
*   **Escala etcd** si tienes mÃ¡s de 5 nodos Patroni (para mantener rendimiento).
*   **Escala HAProxy** si tienes muchos clientes concurrentes.


## âœ… Reglas recomendadas de infraestructura

### 1. ðŸ”¢ **Cantidad mÃ­nima de nodos**

*   **PostgreSQL + Patroni**: mÃ­nimo **2 nodos** (1 maestro + 1 rÃ©plica).
*   **etcd**: mÃ­nimo **3 nodos** para lograr consenso real y tolerancia a fallos.

> âš ï¸ Con solo 1 nodo etcd, no hay consenso distribuido. Se pierde la alta disponibilidad real.

***

### 2. ðŸŒ **Red y conectividad**

*   Los nodos pueden solicitar tener **conectividad directa entre sÃ­** (puertos abiertos).
*   Puertos clave:
    *   `5432`: PostgreSQL
    *   `2379`: etcd client
    *   `2380`: etcd peer
    *   `8008`: Patroni REST API

> ðŸ”’ Se recomienda usar **firewalls internos** y **VPN** si los nodos estÃ¡n en diferentes redes.












Â¡Excelente! Vamos a construir el **manual paso a paso con laboratorio completo** para implementar un clÃºster de **alta disponibilidad en PostgreSQL** usando **Patroni + etcd**, sin balanceadores, con tres nodos PostgreSQL y tres nodos etcd que se comunican entre sÃ­ como un clÃºster distribuido.

***

## ðŸ§­ Manual TÃ©cnico: Laboratorio de Alta Disponibilidad en PostgreSQL con Patroni y etcd (sin balanceadores)

***

### 1. ðŸ“‘ Ãndice

1.  Objetivo
2.  Requisitos
6.  SimulaciÃ³n de Empresa
7.  Estructura SemÃ¡ntica
8.  VisualizaciÃ³n de Arquitectura
9.  Procedimientos TÃ©cnicos
    *   AsignaciÃ³n de IPs y hostnames
    *   InstalaciÃ³n de etcd en clÃºster
    *   InstalaciÃ³n de Patroni en PostgreSQL
    *   ConfiguraciÃ³n de replicaciÃ³n
    *   ValidaciÃ³n de HA
10. Consideraciones Finales
11. Buenas PrÃ¡cticas
12. Recomendaciones
13. BibliografÃ­a

***

### 2. ðŸŽ¯ Objetivo

Implementar un laboratorio funcional de alta disponibilidad para PostgreSQL utilizando **Patroni** como orquestador y **etcd** como almacÃ©n distribuido de estado, sin balanceadores como HAProxy o Pgpool-II. El sistema debe permitir failover automÃ¡tico entre nodos PostgreSQL y mantener la integridad de los datos. Migrando  a **Patroni** sin perder la base de datos productiva, y que Patroni tome el control del clÃºster para gestionar la alta disponibilidad.

***

### 3. âš™ï¸ Requisitos

*   6 servidores Ubuntu 22.04 LTS (mÃ­nimo 2 vCPU, 2 GB RAM)
*   Acceso root o sudo
*   Conectividad entre nodos (puertos: 5432, 8008, 2379, 2380)
*   PostgreSQL 14 o superior
*   Patroni
*   etcd
*   Python3 y pip

*** 

### 6. ðŸ¢ SimulaciÃ³n de Empresa

**Empresa ficticia:** *DataSecureMX*\
**Problema:** El servidor PostgreSQL principal falla y deja a la aplicaciÃ³n sin acceso a datos.\
**SoluciÃ³n:** Implementar Patroni + etcd en 3 nodos PostgreSQL y 3 nodos etcd para garantizar alta disponibilidad sin balanceadores.

***

### 7. ðŸ§  Estructura SemÃ¡ntica

```plaintext
â”œâ”€â”€ PostgreSQL Nodes
â”‚   â”œâ”€â”€ node1 (Maestro)
â”‚   â”œâ”€â”€ node2 (Replica)
â”‚   â””â”€â”€ node3 (Replica)
â”œâ”€â”€ etcd Cluster
â”‚   â”œâ”€â”€ etcd1
â”‚   â”œâ”€â”€ etcd2
â”‚   â””â”€â”€ etcd3
```

***

### 8. ðŸ“Š VisualizaciÃ³n de Arquitectura
```mermaid
graph TD
    subgraph etcd_Cluster
        etcd1[etcd-node1 - 10.0.0.110]
        etcd2[etcd-node2 - 10.0.0.111]
        etcd3[etcd-node3 - 10.0.0.112]
        etcd1 --> etcd2
        etcd2 --> etcd3
        etcd3 --> etcd1
    end

    subgraph PostgreSQL_Patroni_Cluster
        patroni1[pg-node1 - 10.0.0.100]
        patroni2[pg-node2 - 10.0.0.101]
        patroni3[pg-node3 - 10.0.0.102]
    end

    etcd1 --> patroni1
    etcd2 --> patroni2
    etcd3 --> patroni3

    patroni1 --> postgres1[PostgreSQL - Lider]
    patroni2 --> postgres2[PostgreSQL - Replica]
    patroni3 --> postgres3[PostgreSQL - Replica] 
```



***

### 9. ðŸ› ï¸ Procedimientos TÃ©cnicos

#### ðŸ”¹ AsignaciÃ³n de IPs y Hostnames

| Nodo  | IP         | Hostname   |
| ----- | ---------- | ---------- |
| node1 | 10.0.0.100 | pg-node1   |
| node2 | 10.0.0.101 | pg-node2   |
| node3 | 10.0.0.102 | pg-node3   |
| etcd1 | 10.0.0.110 | etcd-node1 |
| etcd2 | 10.0.0.111 | etcd-node2 |
| etcd3 | 10.0.0.112 | etcd-node3 |

```bash
sudo hostnamectl set-hostname pg-node1
sudo hostnamectl set-hostname etcd-node1
# Repetir en cada nodo con su hostname correspondiente
```

***

#### ðŸ”¹ InstalaciÃ³n de etcd en clÃºster (en etcd1, etcd2, etcd3)

```bash
sudo apt update
sudo apt install -y etcd
```

##### ConfiguraciÃ³n `/etc/default/etcd` en cada nodo:

**etcd-node1**

```bash
ETCD_NAME="etcd-node1"
ETCD_INITIAL_CLUSTER="etcd-node1=http://10.0.0.110:2380,etcd-node2=http://10.0.0.111:2380,etcd-node3=http://10.0.0.112:2380"
ETCD_INITIAL_CLUSTER_STATE="new"
ETCD_INITIAL_ADVERTISE_PEER_URLS="http://10.0.0.110:2380"
ETCD_ADVERTISE_CLIENT_URLS="http://10.0.0.110:2379"
ETCD_LISTEN_PEER_URLS="http://10.0.0.110:2380"
ETCD_LISTEN_CLIENT_URLS="http://10.0.0.110:2379"
```

**Repetir en etcd-node2 y etcd-node3 cambiando IP y nombre**

```bash
sudo systemctl restart etcd
sudo systemctl status etcd
```

***

#### ðŸ”¹ InstalaciÃ³n de Patroni y PostgreSQL (en node1, node2, node3)

 
### ðŸ”’ 1. **Respaldar la base de datos maestra**
Aunque no se espera pÃ©rdida de datos, **haz un respaldo completo** por seguridad:
```bash
pg_dumpall > respaldo.sql
```

### ðŸ›‘ 2. **Detener PostgreSQL en los tres nodos**
Patroni necesita iniciar PostgreSQL por sÃ­ mismo:
```bash
sudo systemctl stop postgresql
```


```bash
sudo apt update
sudo apt upgrade -y

#sudo apt install -y postgresql postgresql-contrib
sudo apt -y install python3 python3-pip python3-yaml  
sudo apt install python3-testresources
sudo pip3 install --upgrade setuptools
sudo pip3 install psycopg2 patroni python-etcd
sudo systemctl stop postgresql

sudo rm -rf /var/lib/postgresql/14/main
sudo mkdir -p /var/lib/postgresql/data

sudo chown postgres:postgres /var/lib/postgresql/data
```

***

### ðŸ”§ C. ConfiguraciÃ³n de PostgreSQL

AsegÃºrate de que `postgresql.conf` tenga:

```conf
listen_addresses = '*'
wal_level = replica
max_wal_senders = 10
hot_standby = on
```


Y en `pg_hba.conf`:

```conf
host replication replicator 10.0.0.0/24 md5
```

Crear usuario replicador:

```bash
psql -U postgres
CREATE USER replicator REPLICATION LOGIN ENCRYPTED PASSWORD 'replicatorpass';
```



#### ðŸ”¹ ConfiguraciÃ³n de Patroni

**Archivo `/etc/patroni.yml` en node1 (maestro)**

```yaml
# Nombre del clÃºster y nodo
scope: pg_cluster              # Identificador del clÃºster Patroni
namespace: /service/           # Prefijo en etcd para almacenar la configuraciÃ³n
name: pg-node1                 # Nombre del nodo actual

# ConfiguraciÃ³n de la API REST de Patroni
restapi:
  listen: 10.0.0.100:8008      # DirecciÃ³n IP y puerto donde escucha la API REST
  connect_address: 10.0.0.100:8008  # DirecciÃ³n IP y puerto para que otros nodos se conecten

# ConfiguraciÃ³n de etcd (coordinador de alta disponibilidad)
etcd:
  host: 10.0.0.110:2379,10.0.0.111:2379,10.0.0.112:2379  # IPs de los nodos etcd

# ConfiguraciÃ³n de arranque del clÃºster
bootstrap:
  dcs:
    ttl: 30                        # Tiempo de vida de la sesiÃ³n en etcd
    loop_wait: 10                 # Intervalo entre ciclos de verificaciÃ³n
    retry_timeout: 10            # Tiempo de espera para reintentar operaciones
    maximum_lag_on_failover: 10485760  # MÃ¡ximo lag permitido para hacer failover
    master_start_timeout: 300    # Tiempo mÃ¡ximo para que el nodo maestro arranque
    postgresql:
      use_pg_rewind: true        # Permite usar pg_rewind para sincronizar nodos
      use_slots: true            # Habilita replication slots

  # InicializaciÃ³n de la base de datos (descomentarlo si se desea inicializar)
  #initdb:
  #  - encoding: UTF8
  #  - locale: en_US.UTF-8

  #initdb: [] # En caso de no ocupar inicializar usar este 

  # ConfiguraciÃ³n de acceso (pg_hba.conf)
  pg_hba:
    - host replication replicator 10.0.0.100/32 trust  # Permite replicaciÃ³n desde nodo 1
    - host replication replicator 10.0.0.101/32 trust  # Permite replicaciÃ³n desde nodo 2
    - host replication replicator 10.0.0.102/32 trust  # Permite replicaciÃ³n desde nodo 3
    - host all all 0.0.0.0/0 md5                       # Permite acceso general con contraseÃ±a

  # Usuarios iniciales
  users:
    admin:
      password: admin@123
      options:
        - superuser
    replicator:
      password: rep-pass
      options:
        - replication

  # ConfiguraciÃ³n de clonaciÃ³n (para nodos esclavos)
  clone:
    method: basebackup         # MÃ©todo de clonaciÃ³n
    host: IP_DEL_MAESTRO       # IP del nodo maestro
    user: replicator           # Usuario de replicaciÃ³n
    password: rep-pass         # ContraseÃ±a del usuario de replicaciÃ³n

# ConfiguraciÃ³n de PostgreSQL
postgresql:
  listen: 10.0.0.100:5432         # IP y puerto donde escucha PostgreSQL
  connect_address: 10.0.0.100:5432  # IP y puerto para que otros nodos se conecten
  data_dir: /var/lib/postgresql/data  # Directorio de datos de PostgreSQL
  bin_dir: /usr/lib/postgresql/14/bin # Ruta de los binarios de PostgreSQL

  # AutenticaciÃ³n
  authentication:
    replication:
      username: replicator
      password: admin@123
    superuser:
      username: postgres
      password: admin@123

  # ParÃ¡metros de configuraciÃ³n de PostgreSQL
  parameters:
    wal_level: replica             # Nivel de WAL para replicaciÃ³n
    hot_standby: 'on'              # Permite consultas en nodos esclavos
    max_wal_senders: 10            # MÃ¡ximo nÃºmero de procesos de envÃ­o de WAL
    max_replication_slots: 10      # MÃ¡ximo nÃºmero de replication slots
    archive_mode: 'off'            # Desactiva archivado de WAL
    restore_command: 'false'       # Comando de restauraciÃ³n (no usado aquÃ­)

# Etiquetas del nodo (usadas por Patroni para decisiones de failover y balanceo)
tags:
  nofailover: false               # Permite que este nodo participe en failover
  noloadbalance: false            # Permite que este nodo reciba trÃ¡fico
  clonefrom: false                # Indica si este nodo debe clonarse desde otro
```

**En node2 y node3**: mismo archivo pero sin secciÃ³n `bootstrap`, y con IPs correspondientes.

***

#### ðŸ”¹ Servicio Systemd para Patroni

```ini
[Unit]
Description=Patroni PostgreSQL HA
After=network.target etcd.service

[Service]
Type=simple
User=postgres
Group=postgres
ExecStart=/usr/bin/python3 -m patroni -c /etc/patroni.yml
Restart=on-failure

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl daemon-reload
sudo systemctl enable patroni
sudo systemctl start patroni

-- Tambien puede iniciarlo asi 
patroni patroni.yml
```

Simular salida:

    INFO: running Patroni
    INFO: initializing a new cluster
    INFO: promoted master
    INFO: watching etcd for changes


***

#### ðŸ”¹ ValidaciÃ³n del clÃºster

```bash
patronictl -c /etc/patroni.yml list
```

**SimulaciÃ³n de salida:**

```plaintext
+ Cluster: pg_cluster (3 nodes) -----------+
| Node     | Role    | State   | TL | Lag  |
|----------|---------|---------|----|------|
| pg-node1 | Leader  | running | 1  | 0    |
| pg-node2 | Replica | running | 1  | 32kB |
| pg-node3 | Replica | running | 1  | 28kB |
```

***




### ðŸ”§ F. VerificaciÃ³n y failover

Simula apagado del nodo principal:

```bash
sudo systemctl stop patroni
```

En segundos, otro nodo serÃ¡ promovido:

    INFO: node secundary1 promoted to master

***

 


### ðŸ” 7. **Verificar el estado del clÃºster**
Puedes usar:
```bash
curl http://localhost:8008
```
 
 

## ðŸ§ª Validaciones importantes

- Verifica que el nodo maestro estÃ© registrado como **lÃ­der**.
- Verifica que los esclavos estÃ©n sincronizados.
- Verifica que la replicaciÃ³n estÃ© funcionando.
- Verifica que los datos productivos estÃ©n intactos.
 

### ðŸ”š Consideraciones Finales

*   AsegÃºrate de que los nodos etcd estÃ©n sincronizados
*   Patroni no requiere balanceadores si las aplicaciones conocen el nodo lÃ­der
*   Puedes usar DNS dinÃ¡mico o scripts para redirigir trÃ¡fico si el lÃ­der cambia

***

### âœ… Buenas PrÃ¡cticas y Recomendaciones

*   Usar claves SSH entre nodos
*   Configura backups automÃ¡ticos
*   Configurar firewall para limitar acceso a puertos
*   Monitorear logs de Patroni y etcd
*   Realizar pruebas de failover periÃ³dicas
*   AÃ±adir TLS a etcd y Patroni
*   Usar `consul` como alternativa a etcd si ya lo tienes en tu infraestructura
*   Integrar con `pgbouncer` si necesitas pooling

 
 
***











 

## ðŸ§  ExplicaciÃ³n clara de cada componente

### ðŸ”¹ Patroni (en cada nodo)

*   Monitorea su propia instancia de PostgreSQL.
*   Expone una **API REST** para saber si estÃ¡ activo, si es lÃ­der, etc.
*   Intenta adquirir el **lock de liderazgo** en etcd.
*   Si lo consigue, **inicia PostgreSQL como maestro**.
*   Si no lo consigue, **inicia como rÃ©plica**.

### ðŸ”¹ etcd (centralizado o distribuido)

*   No tiene PostgreSQL ni Patroni.
*   Solo guarda claves y valores como:
    *   Â¿QuiÃ©n es el lÃ­der actual?
    *   Â¿QuÃ© nodos estÃ¡n vivos?
*   Usa el algoritmo **Raft** para decidir quiÃ©n tiene el lock.
*   Evita que dos nodos sean lÃ­deres al mismo tiempo (*split-brain*).
 

## ðŸ§© ComparaciÃ³n de roles

| Componente  | FunciÃ³n principal                                                   |
| ----------- | ------------------------------------------------------------------- |
| **Patroni** | Orquestador HA, monitorea PostgreSQL, expone API REST, decide lÃ­der |
| **etcd**    | Sistema de consenso, almacena estado del clÃºster, evita conflictos  |



## ðŸ§  Â¿QuiÃ©n expone la API REST?

ðŸ‘‰ **La API REST la expone Patroni**, no etcd.

Cada nodo donde corre Patroni tiene su propia API REST (por defecto en el puerto `8008`), que permite:

*   Consultar el estado del nodo (`/health`, `/status`)
*   Forzar un failover manual
*   Ver si el nodo es lÃ­der o rÃ©plica

```bash
curl http://localhost:8008/health
```

**Respuesta esperada**:

```json
{"state": "running", "role": "master", "server_version": 120005}
```

***

## ðŸ©º Â¿QuiÃ©n valida la salud de cada nodo?

ðŸ‘‰ **Patroni valida la salud de los nodos PostgreSQL**.

Cada instancia de Patroni:

*   Monitorea su propio PostgreSQL local.
*   Verifica si estÃ¡ activo, si responde, si tiene acceso al disco, etc.
*   Reporta su estado a etcd mediante actualizaciones periÃ³dicas.

Patroni no monitorea directamente a otros nodos, pero **usa etcd para saber quÃ© reportan los demÃ¡s**.

***

## ðŸ‘‘ Â¿QuiÃ©n decide quÃ© nodo serÃ¡ el maestro?

ðŸ‘‰ **La decisiÃ³n la toma Patroni**, pero **usa etcd como Ã¡rbitro**.

### Â¿CÃ³mo funciona?

1.  Cada nodo Patroni intenta **adquirir un "lock" de liderazgo** en etcd.
2.  etcd permite que **solo uno lo tenga a la vez** (consenso).
3.  El nodo que obtiene el lock se convierte en **lÃ­der (master)**.
4.  Si el lÃ­der falla, otro nodo intenta adquirir el lock.
5.  Patroni promueve ese nodo a lÃ­der automÃ¡ticamente.

***


## ðŸ§  Â¿QuÃ© funciÃ³n tiene Patroni?

**Patroni** es el **orquestador de alta disponibilidad** para PostgreSQL. Su funciÃ³n principal es:

### ðŸ”¹ *Gestionar el estado del clÃºster PostgreSQL*:

*   Decide quÃ© nodo debe ser el **lÃ­der (primary)**.
*   Promueve automÃ¡ticamente un **replica (standby)** a lÃ­der si el actual falla.
*   Supervisa la salud de los nodos PostgreSQL.
*   Expone una **API REST** para monitoreo y control externo.

### ðŸ”¹ *Automatiza tareas crÃ­ticas*:

*   **Failover automÃ¡tico** sin intervenciÃ³n humana.
*   **InicializaciÃ³n del clÃºster**.
*   **ReplicaciÃ³n entre nodos**.
*   **ConfiguraciÃ³n dinÃ¡mica** de parÃ¡metros PostgreSQL.

***

## ðŸ§  Â¿QuÃ© funciÃ³n tiene etcd?

**etcd** es un **almacenamiento clave-valor distribuido** que actÃºa como el **sistema de consenso** para Patroni.

### ðŸ”¹ *Coordina decisiones entre nodos*:

*   Patroni usa etcd para **registrar el estado del clÃºster**.
*   etcd asegura que **solo un nodo sea lÃ­der** en un momento dado (evita *split-brain*).
*   Sirve como **fuente de verdad compartida** entre todos los nodos Patroni.

### ðŸ”¹ *Alta disponibilidad del consenso*:

*   etcd estÃ¡ diseÃ±ado para ser **tolerante a fallos**.
*   Usa el algoritmo **Raft** para lograr consenso entre mÃºltiples instancias.

***
*   **Patroni** consulta a **etcd** para saber si puede ser lÃ­der.
*   **etcd** mantiene el estado del clÃºster y permite que Patroni tome decisiones coordinadas.

---





â“1. Â¿Los nodos etcd se comunican entre sÃ­ en una topologÃ­a con mÃºltiples instancias?

SÃ­. Cuando hay varios nodos etcd, forman un clÃºster de consenso basado en el algoritmo Raft. Esto significa que:

- Se sincronizan constantemente entre ellos.
- Uno actÃºa como lÃ­der, los demÃ¡s como seguidores.
- El lÃ­der recibe las escrituras y las replica a los demÃ¡s para mantener la consistencia.

---

â“2. Â¿A quÃ© nodo etcd se conecta Patroni cuando hay mÃ¡s de uno?

Patroni se conecta a todos los nodos etcd definidos en su configuraciÃ³n. No depende de un nodo especÃ­fico. En su archivo patroni.yml, se especifica una lista como:

`yaml
etcd:
  hosts: etcd1:2379,etcd2:2379,etcd3:2379
`

Patroni interactÃºa con el clÃºster etcd como un todo, y las operaciones se gestionan por el nodo lÃ­der de etcd.

---

â“3. Â¿QuÃ© ocurre si se cae uno de los nodos etcd en un clÃºster de tres?

- El clÃºster sigue funcionando normalmente mientras haya quorum, es decir, al menos 2 de 3 nodos activos.
- Si el nodo caÃ­do era el lÃ­der, los dos restantes eligen automÃ¡ticamente un nuevo lÃ­der.
- Si caen 2 nodos, el clÃºster pierde el quorum y no puede procesar escrituras, lo que afecta a Patroni y puede detener el failover automÃ¡tico.


â“ Â¿Por quÃ© se recomiendan 3 nodos etcd?

- Para tener quorum (2 de 3 nodos activos).
- Para que el clÃºster etcd pueda elegir nuevo lÃ­der si uno falla.
- Para que Patroni pueda seguir operando incluso si un nodo etcd se cae.


â“ Â¿CuÃ¡ndo funciona etcd?

| Cantidad de nodos etcd | Â¿Funciona? | Â¿Alta disponibilidad? | Â¿Quorum tolerante a fallos? |
|------------------------|------------|------------------------|-----------------------------|
| 1 nodo | âœ… SÃ­ | âŒ No | âŒ No (si se cae, todo falla) |
| 2 nodos | âœ… SÃ­ | âŒ No | âŒ No (si se cae 1, no hay quorum) |
| 3 nodos | âœ… SÃ­ | âœ… SÃ­ | âœ… SÃ­ (puede fallar 1 y seguir operando) |


â“ Â¿Puede funcionar Patroni con un solo nodo etcd?

SÃ­, funciona. Puedes tener:
- 1 nodo etcd
- 3 nodos PostgreSQL con Patroni

En esta configuraciÃ³n, Patroni usa ese Ãºnico etcd como almacÃ©n de estado y coordinaciÃ³n. Mientras ese nodo etcd estÃ© vivo y accesible, el clÃºster funcionarÃ¡ correctamente: habrÃ¡ failover, elecciÃ³n de lÃ­der, etc.

---
â“ Â¿CuÃ¡l es el problema con tener solo un etcd?

- No hay quorum: etcd necesita al menos 2 nodos para formar consenso. Con solo uno, no hay tolerancia a fallos.
- Punto Ãºnico de falla: si ese nodo etcd se cae, Patroni no puede hacer failover, ni cambiar el lÃ­der, ni actualizar el estado del clÃºster.
- Aunque los nodos PostgreSQL seguirÃ¡n funcionando en su estado actual, el clÃºster queda congelado.


â“Â¿Por quÃ© algunas topologÃ­as usan solo 1 nodo etcd?

- Simplicidad: Menos infraestructura, mÃ¡s fÃ¡cil de desplegar.
- Funciona bien... mientras no falle.
- Desventaja crÃ­tica: Si ese Ãºnico nodo etcd se cae, Patroni pierde la capacidad de coordinar el clÃºster. No hay failover, no hay cambios de lÃ­der, y el sistema queda congelado.



### ðŸ§  Â¿QuÃ© es el consenso y el quorum en etcd?

- **Consenso**: Es el proceso mediante el cual los nodos de etcd acuerdan el estado actual del sistema (por ejemplo, quiÃ©n es el lÃ­der).
- **Quorum**: Es el nÃºmero mÃ­nimo de nodos que deben estar de acuerdo para tomar decisiones. En etcd, el quorum es **mayorÃ­a simple**:  
  - En un clÃºster de 3 nodos, el quorum es 2.  
  - En un clÃºster de 5 nodos, el quorum es 3.
 
### âš ï¸ Â¿QuÃ© pasa si tienes solo un nodo etcd?

- **No hay quorum**, porque no hay otros nodos con los que llegar a un acuerdo.
- El nodo Ãºnico **no puede tolerar fallos**. Si se cae:
  - Patroni **no podrÃ¡ hacer failover automÃ¡tico**.
  - No se podrÃ¡n escribir ni leer estados de liderazgo.
  - La alta disponibilidad queda **inactiva** hasta que etcd se recupere.

 
### âœ… Â¿Por quÃ© puede funcionar igual?

- Mientras el nodo etcd estÃ© **activo y saludable**, Patroni puede operar normalmente.
- Es Ãºtil para **entornos de desarrollo, pruebas o laboratorios** donde la tolerancia a fallos no es crÃ­tica.



### ðŸ§© ConclusiÃ³n

Tu topologÃ­a **funciona**, pero **no tiene consenso ni quorum**, lo que significa que **no es tolerante a fallos**. Para producciÃ³n, se recomienda:

- **etcd en clÃºster de 3 o 5 nodos**.
- Patroni configurado para usar ese clÃºster.
- Opcional: monitoreo con herramientas como `Prometheus + Grafana`.



***

## ðŸ”¢ Â¿CuÃ¡ntos se recomiendan de cada uno?

| Componente           | MÃ­nimo         | Recomendado | JustificaciÃ³n                              |
| -------------------- | -------------- | ----------- | ------------------------------------------ |
| PostgreSQL + Patroni | 2 nodos        | 3 nodos     | Para tener 1 maestro y al menos 2 rÃ©plicas |
| etcd                 | 1 nodo (no HA) | 3 nodos     | Para consenso real y tolerancia a fallos, pueden ser contenedores   |
| HAProxy / PgBouncer / PgPool  | 1 nodo         | 2 nodos     | Para balanceo y tolerancia a fallos        |
| Prometheus / Grafana | Opcional       | 1 nodo      | Para monitoreo del clÃºster                 |


---

## ðŸ“ Notas importantes

*   etcd **no sabe nada de PostgreSQL**, solo guarda claves y valores.
*   Patroni **sÃ­ entiende PostgreSQL**, y toma decisiones basadas en su estado.
*   La API REST es Ãºtil para monitoreo, automatizaciÃ³n y pruebas.


--- 
### âœ… 1. Â¿CÃ³mo validar que el archivo `patroni.yml` es correcto?

Puedes hacerlo de varias formas:

#### **a. ValidaciÃ³n sintÃ¡ctica del YAML**
Usa herramientas como:

- **`yamllint`** (instalable con `pip install yamllint`):
  ```bash
  yamllint /etc/patroni.yml
  ```

- **Validadores online** como https://www.yamllint.com

Esto asegura que la estructura del archivo es vÃ¡lida, aunque no verifica si los valores son correctos para Patroni.

#### **b. ValidaciÃ³n funcional**
Una vez que Patroni estÃ¡ instalado, puedes correr:

```bash
patroni /etc/patroni.yml
```

Si hay errores, Patroni los mostrarÃ¡ en consola. Si todo estÃ¡ bien, iniciarÃ¡ el servicio y comenzarÃ¡ a gestionar el nodo.

---

### âœ… 2. Â¿DÃ³nde se generan los logs de Patroni?

Por defecto, Patroni **escribe los logs en la consola**. Para redirigirlos a un archivo, puedes:

- Usar `systemd` y configurar el servicio para que los logs se vayan a `journalctl`:
  ```bash
  journalctl -u patroni -f
  ```

- O modificar el archivo `patroni.yml` para incluir una secciÃ³n de logging:

```yaml
logging:
  level: INFO
  format: '%(asctime)s %(levelname)s: %(message)s'
  logfile: /var/log/patroni.log
```

---

### âœ… 3. Â¿El archivo `patroni.yml` debe ser igual en todos los nodos?

**No exactamente.** Aunque la estructura general es la misma, **cada nodo debe tener su propia configuraciÃ³n especÃ­fica**, especialmente en estas secciones:

#### ðŸ” Diferencias por nodo:

| SecciÃ³n         | Nodo Maestro | Nodo Esclavo |
|----------------|--------------|--------------|
| `name:`        | `pg-node1`   | `pg-node2`, `pg-node3` |
| `listen:` / `connect_address:` | IP del nodo actual | IP del nodo actual |
| `data_dir:`    | Ruta local del nodo | Ruta local del nodo |
| `clone:`       | No se usa (en maestro) | Se usa para clonar desde el maestro |
| `pg_hba:`      | Puede ser igual | Puede ser igual |
| `authentication:` | Igual | Igual |
| `tags:`        | Puede variar (por ejemplo, `nofailover: true` si no quieres que un nodo participe en failover) |

---

### âœ… 4. Â¿CÃ³mo integrar los esclavos a Patroni si ya estÃ¡n replicando?

Si ya tienes replicaciÃ³n configurada, puedes:

1. **Detener PostgreSQL en los esclavos.**
2. **Configurar `patroni.yml` en cada esclavo**, asegurÃ¡ndote de:
   - Usar el mismo `scope` y `namespace`.
   - Cambiar `name`, `listen`, `connect_address`, `data_dir`.
   - Configurar correctamente la secciÃ³n `clone:` si quieres que Patroni gestione la clonaciÃ³n.
3. **Iniciar Patroni en cada esclavo.**
4. Patroni detectarÃ¡ el maestro y sincronizarÃ¡ los esclavos automÃ¡ticamente.


## Links
```conf
https://medium.com/@yaseminbsra.sergen/postgresql-with-patroni-high-availability-and-backup-integration-1fd97bffbac1
https://medium.com/@jramcloud1/set-up-high-availability-postgresql-cluster-using-patroni-1367c72fbedb
Patroni -> https://medium.com/@joaovic32/demystifying-high-availability-postgresql-with-patroni-and-pgpool-ii-on-ubuntu-428c91a55b1a
https://ozwizard.medium.com/postgresql-with-patroni-installation-and-configuration-49d6b8105580

*   <https://github.com/zalando/patroni>
*   <https://etcd.io/docs/>
*   <https://www.postgresql.org/docs/current/warm-standby.html>

```
